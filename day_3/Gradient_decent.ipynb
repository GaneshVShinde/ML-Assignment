{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actual function is (x-2)**2 ----> derivative ---> 2(x-2)\n",
    "def der_(x):\n",
    "    return (x-2)*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_x = 6  # We start the search at x=6\n",
    "gamma = 0.01  # Step size multiplier\n",
    "precision = 0.00001  # Desired precision of result\n",
    "max_iters = 10000  # Maximum number of iterations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_decent(next_x,func):\n",
    "    for _i in range(max_iters):\n",
    "        current_x = next_x\n",
    "        next_x = current_x - gamma * func(current_x)\n",
    "\n",
    "        step = next_x - current_x\n",
    "        if abs(step) <= precision:\n",
    "            break\n",
    "\n",
    "    print(\"Minimum at {}\".format(next_x))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum at 2.000488528325998\n"
     ]
    }
   ],
   "source": [
    "gradient_decent(next_x,der_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The wholesale price of a designer shirt is $25. A retail store\n",
    "has determined that if they sell the shirt for $40, consumers\n",
    "will purchase 55 shirts per month. The manager of the menâ€™s\n",
    "department knows that for each dollar decrease in price, 5\n",
    "more shirts will be sold each month. What selling price will\n",
    "yield the greatest monthly profit for the store?\n",
    "\n",
    "\n",
    "write code to solve above question using gradient ascent/descent "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximize function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def der_2(x):\n",
    "    return(14-10*(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_x = 27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gradient_ascent(next_x,func):\n",
    "    for _i in range(max_iters):\n",
    "        current_x=next_x\n",
    "        next_x = current_x + gamma * func(current_x)\n",
    "\n",
    "        step=next_x-current_x\n",
    "\n",
    "        step = next_x - current_x\n",
    "        if abs(step) <= precision:\n",
    "            break\n",
    "\n",
    "    print(\"Maximum at {}\".format(next_x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum at 1.400088514925052\n"
     ]
    }
   ],
   "source": [
    "gradient_ascent(39,der_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multidimensional gradient decent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function is x^2+y^2\n",
    "next_x=np.float32([100,200])\n",
    "def par_der(x,y):\n",
    "    return np.float32([2*x,2*y]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum at x:0.00016188606969080865 y:0.0003237721393816173\n"
     ]
    }
   ],
   "source": [
    "old_sum=0\n",
    "for i in range(max_iters):\n",
    "    current_x = next_x\n",
    "    \n",
    "    next_x=current_x - gamma*par_der(current_x[0],current_x[1])\n",
    "    \n",
    "    if abs(np.sum(next_x)-np.sum(current_x))<precision:\n",
    "        break\n",
    "\n",
    "print(\"Minimum at x:{} y:{}\".format(next_x[0],next_x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# https://en.wikipedia.org/wiki/Test_functions_for_optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## take any multivariate function from above link and optimize it to minima/maxima(optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# f(x,z) = 2z^3* x^2 \n",
    "optimize above function using gradient descent \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
